\section{Optimizations of population protocols}
%% TEXT %%
The population protocol in section \ref{Section3} solved the approximate majority problem. This, however, limits the use cases of the protocol as it requires some specific initial bias to converge to the correct solution.  In this section a stable nonuniform population protocol, presented by Doty et al. in \cite{dotyTimeSpaceOptimal2022}, that solves the \emph{exact} majority problem when $k = 2$. 

\subsection{Notation and definitions}

A \emph{nonuniform} population protocol is one where the set of transitions used for a specific population size $n$, depends on the value $\lceil \log n \rceil$. Essentially this means that in a nonuniform protocol, for different population sizes $n$, different pairs of $Q$ and $\delta$ are allowed (up to $\lceil \log n \rceil$ combinations). In \cite{dotyTimeSpaceOptimal2022}, all of these combinations combined are referred to as a single protocol. 

Initially each agent has a \emph{bias}: $+1$ for opinion $x$ and $-1$ for opinion $y$. Let the \emph{initial gap} be the sum over the entire population $g = \sum_v v.bias$. $g$ is maintained as an invariant. 

Let the constant $L = \lceil \log n \rceil$ be the number of different values (or biases) an agent in the system can store. For an agent to be able to store $L$ different values, $\log \log n \ + \ O(1)$ bits of memory are needed. Through the agents' interactions with each other, they modify their opinion to any value in the following set: $\{ 0, \pm \frac{1}{2}, \pm \frac{1}{4}, ...,  \pm \frac{1}{2^L} \}$. The interactions happen through two types of interactions: \emph{cancel reactions} $(+\frac{1}{2^i}, -\frac{1}{2^i}) \mapsto (0, 0)$ and \emph{split reactions} $(\pm \frac{1}{2^i}, 0) \mapsto (\pm \frac{1}{2^{i + 1}}, \pm \frac{1}{2^{i + 1}})$.

The \emph{gap} in the protocol is defined by the sum over the entire population: \\ \mbox{$\sum_v$ sign($v.bias$)}.

Let $c$ be an agent in a sub-population of clock agents. \emph{Drip reactions} for the sub-population are the following: $(c_i, c_i) \mapsto (c_i, c_{i + 1})$. \emph{Epidemic reactions} for the same population are: $(c_i, c_j) \mapsto (c_{max(i, j)}, c_{max(i, j)})$.

\subsection{High-level overview}

The main idea of the protocol is to have agents interact with each other through cancel and split reactions. The cancel and split reactions average the bias between the two agents interacting with each other, however only when the resulting average is a power of 2 or 0. The acceptable biases are any value in the following set $\{ 0, \pm \frac{1}{2}, \pm \frac{1}{4}, ...,  \pm \frac{1}{2^L} \}$. $L$ ensures that $\Theta(\log n)$ possible values of \emph{bias} that any agent must be able to store. If this was not the case, and all averages were accepted, then all bias would converge to $\frac{g}{n}$. This would also consume more than the allowed $\log \log n$ bits of memory per agent. The unbiased agents that are required for the split reactions are partially synchronized with a field \emph{hour}. The addition of the field \emph{hour} requires $\log n$ more memory, for $0_0, 0_1, 0_2, ..., 0_L$. The split reaction with the hour field included looks like
\begin{align}
    (\pm \frac{1}{2_i}, 0_h) \mapsto (\pm \frac{1}{2^{i + 1}}, \pm \frac{1}{2^{i + 1}}) \text{      if, } h > i.  \label{splitreaction}
\end{align}
The new split reaction \ref{splitreaction} will also hold until $hour \geq h$ before executing a split reaction that results in $bias = \pm \frac{1}{2^h}$. In \cite{dotyTimeSpaceOptimal2022}, a fast clock using $O(1)$ time per hour is used. The aforementioned \emph{hour} field, used by unbiased agents is synchronized to a different population (still part of $n$) of clock agents, that instead of \emph{hour}, use the field \emph{minute}. In one \emph{hour} there are $k$ consecutive $minutes$. Within this population of clock agents, $minutes$ tick forward using drip reactions and catch up using epidemic reactions. Due to $O(1)$ not being enough time to synchronize all agents, only a large constant of agents will be synchronized to the latest \emph{hour}. Doty et al. proves in \cite{dotyTimeSpaceOptimal2022} that even though not all agents are up to date, the synchronization keeps the $hour$ and $bias$ sufficiently concentrated.

To clean up all agents with the incorrect opinion, the protocol uses a new population of agents, called \emph{Reserve} agents, that enable more split reactions for agents with large bias values of $|bias| > \frac{1}{2^l}$. After this and after cancel reactions with the majority agents, all agents with the minority opinion still left must have $|bias| < \frac{1}{2^{l + 2}}$. 

At this point, there are still agents with the minority opinion left that have a small bias. To get rid of these, other agents that have larger bias \emph{consume} them. In \cite{dotyTimeSpaceOptimal2022}, the example of agents with bias $+ \frac{1}{4}$ and $- \frac{1}{256}$ is used. In this example, the positive agent can be seen as "holding" the entire bias $+ \frac{1}{4} - \frac{1}{256} = + \frac{63}{256}$. This value is, however, not in the accepted values. Due to this, it can no longer participate in future averaging interactions. In \cite{dotyTimeSpaceOptimal2022}, however, it is shown that with high probability there are enough majority agents to eliminate all of the remaining minority agents through the previously described \emph{consumption reactions}.

The final part of the protocol checks for positive and negative bias. If one has been removed completely, the system stabilizes to the correct output. If there still are both positive and negative biases, some error has occurred.

In the case of a tie, meaning an equal size of opinion $x$ and $y$ in the initial configuration, this protocol detects it with high probability. In an initial configuration where a tie is present, $g = 0$. And with high probability, Doty et al. shows in \cite{dotyTimeSpaceOptimal2022}, that all agents will finish with $bias \in \{ 0, \pm \frac{1}{2^L} \}$. 


\subsection{Results} \label{Section4Results}

The main theorem in \cite{dotyTimeSpaceOptimal2022} is slightly modified to create the following theorem: 

 \begin{theorem}\thlabel{theorem6}
    \textit{
        There is a non-uniform population protocol Nonuniform-Majority, using agents capable of storing $O(\log n)$ different values, that stably computes the majority in $O(\log n)$ stabilization time, both in expectation and with high probability.
    }
 \end{theorem} 

The protocol that Doty et al. presents in \cite{dotyTimeSpaceOptimal2022} is capable of quickly solving the exact majority problem in $O(\log n)$ time with high probability using $\log \log n + O(1)$ bits of memory to store $O(\log n)$ different values. The protocol is nonuniform, meaning that all agents must have an estimate of $\lceil \log n \rceil$ embedded in the transition function. Essentially this means that the number of values $L$ any agent must be capable of storing is a function of $n$. Doty et al. also discuss how the protocol would behave as a uniform protocol, however, the protocol would no longer be space optimal due to it needing the memory to store $O(\log n \log \log n)$ different values in each agent. 

In comparison to the undecided state dynamics protocol presented by Angluin et al. in \cite{angluinSimplePopulationProtocol2008} and discussed in section \ref{Section3}, the Nonuniform-Majority protocol solves the exact majority problem, making it much more usable. It is also faster, reaching consensus with high probability in $O(\log n)$ time, as the USD protocol while solving the exact majority problem. The drawback of the quickness is the use of memory, as the Nonuniform-Majority protocol uses $O(\log \log n)$ bits of memory.  The protocol is also limited to $k = 2$, meaning the decision is only based on two input opinions. 
Additionally, due to the non-uniformity, the protocol is dependent on the input size $n$, and the agents need to know this. This essentially means all agents in the system need to know how many agents there are in the system before starting the execution, which is not wanted in many cases. 


% ------------------------------------------------
% GENERALIZAITON
\subsection{Generalization}

In a recent paper by Bankhamer et al. (\cite{bankhamerPopulationProtocolsExact2022}), the protocol discussed in \ref{Section4Results} was extended to support $k > 0$ initial opinions.
While it is known that any always correct protocol requires memory capable of storing $\Omega(k^2)$ states per agent, Bankhamer et al. reduce this drastically by allowing some insignificant failure probability \cite{ongaroSearchUnderstandableConsensus}. 

\subsubsection{Protocols} \label{441}

In \cite{bankhamerPopulationProtocolsExact2022} presents a protocol for solving the exact majority problem for an arbitrary number $k$ opinions, where $k > 2$. Three protocols are presented. The first one called \emph{simple algorithm}, relies on the ordering of the states from 1 to $k$ to eliminate non-majority in $k-1$ tournaments. The second protocol removes the reliance on the ordering of states but sacrifices some time making it slower to reach consensus. The final protocol, called \emph{improved algorithm}, removes insignificant states before starting the tournaments, cutting time to consensus significantly. 

The simple algorithm performs a sequence of \emph{tournaments}, that each takes $O(\log n)$ time. These tournaments are synchronized by a \emph{phase clock}. In a tournament, two opinions are chosen and an exact majority protocol is used to determine which one of the opinions populations is larger (i.e. which one has majority). The tournaments begin from opinions 1 and 2 and work their way up until the last opinion when the majority will be the majority of the whole system. Described more formally, if $i > 1$ is the number of tournaments performed, the winner of the previous tournament $i - 1$, called \emph{defender}, will be put in a tournament against opinion $i + 1$, called \emph{challenger}. 

The improved algorithm works in a similar fashion, however, implements a mechanism to get rid of insignificant opinions before starting the iterations of tournaments. Very briefly, before every tournament iteration starts, every agent has a counter that counts interactions with the agents with the same opinion. The first counter to reach a fixed value $t \in O(\log n)$ triggers the beginning of the tournaments. All agents with a counter of under $\frac{t}{2}$ will not participate in the tournament iterations. This removal of insignificant opinions lowers the required amount of tournaments to $O(\frac{n}{x_{max}})$. This drastically improves the time of the protocol. More detailed descriptions of both algorithms can be found in \cite{bankhamerPopulationProtocolsExact2022}.

\subsubsection{Results}

The main result Bankhamer et al. presents in \cite{bankhamerPopulationProtocolsExact2022} is the improved algorithm briefly described in section \ref{441}. The following theorem is a slightly modified version (to match preliminaries and notations of this paper) of the main result of \cite{bankhamerPopulationProtocolsExact2022}

 \begin{theorem}\thlabel{theorem7}
    \textit{
        Assume we have a population of size $n$ with $k$ initial opinions where $x_{max} > n^{\frac{1}{2 + \varepsilon}}$ for some small constant $\frac{1}{2} > \varepsilon > 0$. The \emph{improved algorithm} converges with high probability to the majority opinion in $O(\frac{n}{x_{max} \cdot \log n + \log^2 n})$ time while requiring agents to be capable of storing $O(k \cdot \log \log n + \log n)$ different values.}
 \end{theorem} 

The \emph{improved algorithm} in \cite{bankhamerPopulationProtocolsExact2022} expands the Nonuniform-Majority protocol from \thref{theorem6} (from \cite{dotyTimeSpaceOptimal2022}) to create a protocol for $k > 2$ number of initial opinions. This protocol solves the exact majority problem with high probability quickly while only requiring the agents to be able to store $O(k + \log n)$ values. 
