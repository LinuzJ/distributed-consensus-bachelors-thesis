%% SYMBOLS AND ABBREVIATIONS
\section{Preliminaries}

%%------------------------------------------------------------------------------------
%% BIG O
\subsection{Big O notation}

 The Big O is a notation describing the execution time of an algorithm, either through memory or time usage. It is the asymptotic upper bound of a function that describes the algorithm. In computer science the Big O notation is used to analyze the time and space complexity of algorithms. and The Big O notation is a function of \inlineMath{n}, where \inlineMath{n} is the number of items handled in the algorithm. Described informally using the equation \inlineMath{f(n) = O(g(n))}, \inlineMath{f(n)} is smaller than some constant multiplied with \inlineMath{g(n)}.

 \begin{definition}
 We write \inlineMath{f(n) = O(g(n))}, if there exists a constant
 \inlineMath{c > 0} and \inlineMath{k > 0}, such that \inlineMath{0 \leq f(n) \leq cg(n) \: \forall \: n \geq k}
 \end{definition}
\subsection{Distributed system}

A distributed system is a set of networked computers, which coordinate their actions through communicating by messages. A distributed system can be modelled as a single coherent system. We can define this system as a set of nodes, connected in a network, that collectively coordinate and execute tasks.

Let the communication network of the distributed system be a graph \inlineMath{G = (V, E)}, where \inlineMath{V} is the set of vertices (or nodes), meaning the computing entities, or processes, of the system and \inlineMath{E} is the set of edges in the system that make up the communication links between the edges. The terms agent, node will be used interchangeably. 

Each individual node, or process, in the set of nodes \inlineMath{V} has an internal state \inlineMath{S_p = (x_p, y_p)}, where \inlineMath{x_p} is a one-bit \emph{input register} and \inlineMath{y_p} a one-bit \emph{output register} with values in \inlineMath{\{b, 0, 1\}}, where \inlineMath{b} is a \emph{blank} state. Let the state of the system be  \inlineMath{S = (S_1, S_2, ...., S_N)}, where \inlineMath{N} is the amount of nodes in the system. The behaviour of the system can be a set of rule of how the nodes interact with each other, altering the individual internal states of nodes and edges. These rules can be formalized as a set of functions \inlineMath{F}, that map the current state of the system \inlineMath{S} to a new state \inlineMath{S'}.

Define a distributed system as a tuple \inlineMath{(V, E, S, F)}, where \inlineMath{V} is the set of vertices (or nodes), \inlineMath{E} is the set of communication links between nodes, \inlineMath{S} is the current state of the system and \inlineMath{F} is the set of functions that define the behaviour of the system.

%%------------------------------------------------------------------------------------
%% CONSENSUS PROBLEM
\subsection{Consensus problem}

The consensus problem asks to design a protocol that requires all computing entities, called agents, in a system, to agree on a binary value. This system of agent may include faulty agents, that may fail or produce faulty messages. The challenge is to make all non-faulty agents to have a shared understanding of the binary value in question, even with the presence of faulty agents. 

In order to reach consensus, each node in the set \inlineMath{V}, which is the set of nodes in the system, begins by \emph{proposing} the value in it's \emph{input register} \inlineMath{x_p}. Let the value proposed be \inlineMath{v_i}. The nodes then communicate and share their initial proposals. The nodes then decide on a decision value \inlineMath{d_i} and sets it in their respective \emph{output registers} \inlineMath{y_p}. The nodes are now in the \emph{decided state}, from which they can no longer return nor change the value of \inlineMath{y_p}. The requirements of a consensus algorithm are that, for each execution of it, these conditions should hold:

\begin{itemize}[label={}]
  \item \emph{Termination:} All correct nodes eventually sets the value of their output register and reach a decided state.
  \item \emph{Agreement:} All correct nodes share the same value in their output registers: if \inlineMath{V_i} and \inlineMath{V_j} are correct nodes and are in the \emph{decided state}, their corresponding states \inlineMath{S_i} and \inlineMath{S_j} share the same \emph{output register} values \inlineMath{y_i = y_j}.
  \item \emph{Integrity:} If all correct nodes proposed the same value, then any correct node that is in the \emph{decided state} has chosen that value.
\end{itemize}

\linus{% First define it in a classic setting,
% then define with randomized properties

% impossibility result
}


%% Insert explanation on the graph below
In Figure \ref{fig:ConsensusProblem} we can see an example of the explanation above. Two nodes propose \emph{proceed} and the third node proposes \emph{abort}, but crashes thereafter. The two correct nodes that remain decide on \emph{proceed}.
\begin{figure}[H]
    \centering
    \includesvg[width = 0.7\textwidth]{figures/consensus_problem.svg}
    \caption{Consensus for three processes}
    \label{fig:ConsensusProblem}
\end{figure}


\linus{Elaborate figure \ref{fig:ConsensusProblem}}

%%------------------------------------------------------------------------------------
%% MAJORITY CONSENSUS
\subsection{Majority Consensus}

In the classical consensus problem, consensus is reached when all correct nodes eventually reaches a decided, or finished state. This value may be whatever, as long as all of the correct nodes share the same value in their decided state. However, \emph{majority} consensus requires the algorithm to agree on the initially most frequent value.

\begin{definition}
In a system with \inlineMath{n} agents and \inlineMath{k} states. Majority consensus is reached when the agents have agreed on the most frequently occurring initial state. 
\end{definition}
 
 \emph{Exact} majority consensus is a requirement that the agreement must me made correctly even though the initially most frequent and second most frequent only differ in size by 1. In literature, the terms \emph{majority} and \emph{plurality} are often used interchangeably. \emph{Majority} will be used in this thesis for consistency.


%%------------------------------------------------------------------------------------
%% ASYNC AND SYNC SYSTEMS
\subsection{Asynchronous and synchronous systems}

When modelling a theoretical system, one can either choose to model it as a synchronous system or as a asynchronous system. In a synchronous system, all agents essentially use the same clock. The algorithms used in a synchronous system assume that steps take place in discrete rounds. A agent can be assumed to be faulty if no message has been received from it at the end of the round. In a asynchronous system on the other hand, agents can send messages at arbitrary times, meaning that if an agent fails, it is indistinguishable from an agent responding slowly.


%%------------------------------------------------------------------------------------
%% POPULATION PROTOCOLS
\subsection{Population protocol}
 A population protocol is a theoretical model used for modelling collections of agents capable of moving, interacting and computation. The goal of the protocol is for the collection of agents to converge towards a correct output value. In the basic population protocol model, an input value is distributed to the the collection of agents. Agents have pairwise interaction in the order set by a scheduler, subject to some fairness guarantee. Each agent in the collection is a type of finite state machine and the protocol for the system describes how the the interaction between two agents change their respective states. No failures occur for the agents in the system. The output values of the agents change over time and eventually, they must converge to the correct output value for the set of input values initially distributed to the agents \cite{aspnesIntroductionPopulationProtocols2009}. 

 A protocol is formally defined by
 \begin{itemize}
     \item \inlineMath{Q}, a finite set of possible states for an agent,
     \item $\Sigma$, a finite input alphabet,
     \item $\zeta$, an input map $\Sigma \mapsto Q$, where $\zeta(\sigma)$ represents the initial state of an agent and the input to that agent is $\sigma$,
     \item $\omega$, an output map $Q \mapsto Y$, where $Y$ is the output range and $\omega(q)$ represents the output value of an agent in state $q$,
     \item $\delta \subseteq Q \times Q \mapsto Q \times Q$, a transition relation that describes interactions between agents.
     
 \end{itemize}

A computation following a protocol defined as above, proceeds as follows. Let the system have \inlineMath{n} \emph{agents}, where \inlineMath{n \geq 2}. And let the computation take place in the system mentioned previously. The input value for each agent in the system is a value from $\Sigma$. The initial state is determined by using $\zeta$ on all agents input values. Let the \emph{configuration} of the system be a vector \inlineMath{C} that contains all the states of the agents. 

A protocol is made up of many executions. An execution alters the \emph{configuration} of the system through pairwise interaction between agents. During each execution step, a pair of agents \inlineMath{(v, w)} are chosen at random. Interactions are usually asymmetric, meaning one agent (\inlineMath{v}) acts as the \emph{initiator} and the other \inlineMath{(w)} acts as the \emph{responder}. The chosen pair pf agents have the states \inlineMath{q_1} and \inlineMath{q_2}. The agents with states \inlineMath{q_1} and \inlineMath{q_2} can change into the states \inlineMath{q_1'} and \inlineMath{q_2'} if the interaction \inlineMath{(q_1, q_2, q_1', q_2')} is in the transition relation $\delta$. This interaction could also be described using the notation $(q_1, q_2) \mapsto (q_1', q_2')$.  If \inlineMath{C} and \inlineMath{C'} are \emph{configurations} in the system, \inlineMath{C \rightarrow C'} means that \inlineMath{C'} can be reached from \inlineMath{C} through a single interaction. The previously mentioned \emph{execution} of the protocol is an infinite sequence of configurations \inlineMath{C_0, C_1, C_2, ...} where \inlineMath{C_0} is the initial configuration and $C_i \rightarrow C_{i+1} \forall i \geq 0$. 
\\\\
The pairwise interactions between agents occur in an unpredictable order. The sequence of interactions can be thought of as an adversary, under whose decisions the protocol must work correctly. However, in order for significant computations to take place, some restrictions must be places on the adversary scheduler of the system. Otherwise, the adversary scheduler could divide agents into two isolated groups and only schedule pairwise interactions with agents isolated in their own groups.  
\\\\
As stated previously, the systems scheduler is subject to some \emph{fairness} condition. This fairness condition ensures that the scheduler cannot avoid a certain step indefinitely. Expressed more formally: Let \inlineMath{C} be a configuration that exists an infinite amount of times in an execution. If \inlineMath{C \mapsto C'}, then the configuration \inlineMath{C'} also must exist an infinite amount of times in the execution. This can be summarised as the requirement: all potential configurations that can be reached, will eventually be reached.
\\\\ 
The correctness of a population protocol can also be compared to the execution of the algorithm. During the execution of a population protocol, if the state of any given agent at any given time is \inlineMath{q}, then its output value will be \inlineMath{w(q)}. This means that the output of an agent may change during an execution. According to the fairness constraint explained previously, the scheduler of the protocol may schedule arbitrary interactions only up to a certain point. Correctness can also be phrased in a similar way: all agents must eventually produce the correct output, and continue doing so after that point in time.




\linus{TODO: Finish population protocol prelim}

